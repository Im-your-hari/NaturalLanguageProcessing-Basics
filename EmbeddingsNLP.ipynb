{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYwd4t5YN2Sh"
      },
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2Vector**"
      ],
      "metadata": {
        "id": "-fFS5M1AbVFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models"
      ],
      "metadata": {
        "id": "h0zBDRSwN_Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vector = models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz',binary=True)"
      ],
      "metadata": {
        "id": "cP8DnFEzXt1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prebuild Models...\n",
        "'''\n",
        "import gensim.downloader as a\n",
        "print(list(a.info()['models'].keys()))\n",
        "'''"
      ],
      "metadata": {
        "id": "f-nTj4LOYW8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = word2vector['mental health']\n",
        "#vector = word2vector['health']\n",
        "\n",
        "vector"
      ],
      "metadata": {
        "id": "jVfNCtRjYvck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vector) #Model create cheytha vectorsnte ennam.."
      ],
      "metadata": {
        "id": "DBLN147gadxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vector.most_similar('sad')"
      ],
      "metadata": {
        "id": "yoVq9r5fZEuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['J. Robert Oppenheimer (1904–1967) was an American theoretical physicist, best known for his role as the scientific director of the Manhattan Project, the World War II project that developed the first nuclear weapons. ',\n",
        "         'Oppenheimer is often referred to as the \"father of the atomic bomb\" for his leadership in the development of the weapon.',\n",
        "         'Born in New York City, Oppenheimer showed an early aptitude for science and mathematics.',\n",
        "         'He studied at Harvard University, where he earned his bachelors degree in chemistry before pursuing a Ph.D. in physics at the University of Göttingen in Germany. ',\n",
        "         'Oppenheimer made significant contributions to theoretical physics, particularly in the fields of quantum mechanics and astrophysics, before World War II.']\n"
      ],
      "metadata": {
        "id": "q4Nh1E1nZPxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [sentence.split() for sentence in list1] #Sentencele oro word by word aayi tokens create cheythu..."
      ],
      "metadata": {
        "id": "DUTnM7pDZc2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customModel = model.Word2Vec(tokens,min_count=1) #"
      ],
      "metadata": {
        "id": "6EZ5rpJnZtdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customModel.wv.index_to_key[:15]"
      ],
      "metadata": {
        "id": "207987I8aI3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ith custom model aan...\n",
        "customModel.wv.most_similar('scientific')"
      ],
      "metadata": {
        "id": "Pnbxi5ruaSLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom modelil illatha oru word try chythaal kittilla...Bcoz ath mnsilaakkan ulla word nmde sentenceil illa...\n",
        "customModel.wv.most_similar('pandemic')"
      ],
      "metadata": {
        "id": "Ox3WW4pMbq04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ith googlente pre bulid model aan...\n",
        "word2vector.most_similar('scientific')"
      ],
      "metadata": {
        "id": "F5ZVdVBla8WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Glove**"
      ],
      "metadata": {
        "id": "AMGkHKWubcdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import spacial\n",
        "\n",
        "embeddings = {}\n",
        "'''\n",
        "'glove_68/glove.68.50d.txt'  -------->  50 dimention vectors ulla wordlist\n",
        "\n",
        "Eg:-\n",
        "\n",
        "hai 0.123 0.345 0.678.........50 ennam\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "with open('glove_68/glove.68.50d.txt','rb') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.array(values[1:],\"float32\")\n",
        "    embeddings[word] = vector\n",
        "\n"
      ],
      "metadata": {
        "id": "fdaEXBnybgbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Oru wordnte vector aayi relate cheyyan pattunna vectorsilekk euclidean distance vach relations check cheyyunnu....\n",
        "def find_closest_embeddings(embedding):\n",
        "  return sorted(embeddings.keys(), key=lambda word: spacial.distance.euclidean(embeddings[word],embedding))"
      ],
      "metadata": {
        "id": "u7IDadc7fUZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding[b'pandemic']"
      ],
      "metadata": {
        "id": "R0ZpHltDecHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relate cheyyan pattunna words euclidean distance vach kndupidich mnsilaakkunnu...\n",
        "find_closest_embedding(embedding[b'pandemic'])[:10]"
      ],
      "metadata": {
        "id": "aeWMfmyaemOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FastText**-Facebook"
      ],
      "metadata": {
        "id": "Ka90lBrQfkyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "id": "l9abcWFpfzs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from gensim.test.utils import common_texts\n"
      ],
      "metadata": {
        "id": "eAHmLXyvf56L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ftmodel = FastText(vector_size = 4, window=3,min_count=1)\n",
        "ftmodel.build_vocab(corpus_iterable = tokens)\n",
        "ftmodel.train(corpus_iterable=common_texts,total_examples=len(common_texts),epochs=15)"
      ],
      "metadata": {
        "id": "wCHPtEDJgJTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ftmodel.wv.most_similar('pandemic',topn=10)"
      ],
      "metadata": {
        "id": "h8UuDSm6g5Wd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}